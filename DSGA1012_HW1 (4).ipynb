{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "py36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "DSGA1012-HW1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Z8eeN5IW9q"
      },
      "source": [
        "The deadline is 9:30am Feb 9th (Wed).   \n",
        "You should submit a `.ipynb` file with your solutions to BrightSpace.\n",
        "\n",
        "--- \n",
        "\n",
        "There are 10 extra points for \"adding extra features to your model\". But the maximum grade you can obtain in this homework is 100%. If you complete the extra-credit task, your score will be min{10+score, 100}.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In this homework we will preprocess SMS Spam Collection Dataset and train a bag-of-words classifier (logistic regression) for spam detection. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZd0LJzbISPd"
      },
      "source": [
        "## Data Loading (10 points)\n",
        "\n",
        "First, we download the SMS Spam Collection Dataset. The dataset is taken from [Kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset/data#) and loaded to [Google Drive](https://drive.google.com/open?id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR) so that everyone can access it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvGErs2oHkWU"
      },
      "source": [
        "!wget 'https://docs.google.com/uc?export=download&id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR' -O spam.csv "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcHV1lUwtH-n"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXVQCF-ovo4G"
      },
      "source": [
        "There are two columns: `v1` -- spam or ham indicator, `v2` -- text of the message."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiKE89v0zMiY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"spam.csv\", usecols=[\"v1\", \"v2\"], encoding='latin-1')\n",
        "# 1 - spam, 0 - ham\n",
        "df.v1 = (df.v1 == \"spam\").astype(\"int\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXQhTzrCv-Nk"
      },
      "source": [
        "Your task is to split the data to train/dev/test (don't forget to shuffle the data). Make sure that each row appears only in one of the splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga5Qydpw-gdQ"
      },
      "source": [
        "# 0.15 for val, 0.15 for test, 0.7 for train\n",
        "val_size = int(df.shape[0] * 0.15)\n",
        "test_size = int(df.shape[0] * 0.15)\n",
        "\n",
        "\"\"\"\n",
        "YOUR CODE GOES HERE\n",
        "\"\"\"\n",
        "\n",
        "train_texts, train_labels = None, None\n",
        "val_texts, val_labels     = None, None\n",
        "test_texts, test_labels   = None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGyHG4lBISP2"
      },
      "source": [
        "## Data Processing (40 points)\n",
        "\n",
        "The task is to create bag-of-words features: tokenize the text, index each token, represent the sentence as a dictionary of tokens and their counts, limit the vocabulary to $n$ most frequent tokens. In the lab we use built-in `sklearn` function, `sklearn.feature_extraction.text.CountVectorizer`. \n",
        "**In this HW, you are required to implement the `Vectorizer` on your own without using `sklearn` built-in functions.**\n",
        "\n",
        "Function `preprocess_data` takes the list of texts and returns list of (lists of tokens). \n",
        "You may use [spacy](https://spacy.io/) or [nltk](https://www.nltk.org/) text processing libraries in `preprocess_data` function. \n",
        "\n",
        "Class `Vectorizer` is used to vectorize the text and to create a matrix of features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "793EFaQYhHeR"
      },
      "source": [
        "def preprocess_data(data):\n",
        "    # This function should return a list of lists of preprocessed tokens for each message\n",
        "    \"\"\"\n",
        "    YOUR CODE GOES HERE\n",
        "    \"\"\"\n",
        "    preprocessed_data = None\n",
        "    return preprocessed_data\n",
        "\n",
        "train_data = preprocess_data(train_texts)\n",
        "val_data = preprocess_data(val_texts)\n",
        "test_data = preprocess_data(test_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw8z2TjpS3Pv"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM2qpOKpjVbD"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Vectorizer():\n",
        "    def __init__(self, max_features):\n",
        "        self.max_features = max_features\n",
        "        self.vocab_list = None\n",
        "        self.token_to_index = None\n",
        "\n",
        "    def fit(self, dataset):\n",
        "        # Create a vocab list, self.vocab_list, using the most frequent \"max_features\" tokens\n",
        "        # Create a token indexer, self.token_to_index, that will map each token in self.vocab \n",
        "        # to its corresponding index in self.vocab_list\n",
        "        \"\"\"\n",
        "        YOUR CODE GOES HERE\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def transform(self, dataset):\n",
        "        # This function transforms text dataset into a matrix, data_matrix\n",
        "        \"\"\"\n",
        "        YOUR CODE GOES HERE\n",
        "        \"\"\"\n",
        "        data_matrix = np.zeros((len(dataset), len(self.vocab_list)))\n",
        "        \n",
        "        return data_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXMrZXlZjcH7"
      },
      "source": [
        "max_features = None # TODO: Replace None with a number\n",
        "vectorizer = Vectorizer(max_features=max_features)\n",
        "vectorizer.fit(train_data)\n",
        "X_train = vectorizer.transform(train_data)\n",
        "X_val = vectorizer.transform(val_data)\n",
        "X_test = vectorizer.transform(test_data)\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "vocab = vectorizer.vocab_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGLg6udky1zo"
      },
      "source": [
        "(10 extra points) You can add more features to the feature matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s80GgEm6F5DG"
      },
      "source": [
        "\"\"\"\n",
        "YOUR CODE GOES HERE\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtm7a6JWu9-3"
      },
      "source": [
        "## Model\n",
        "\n",
        "We train logistic regression model and save prediction for train, val and test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq9stSAbAIZe"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define Logistic Regression model\n",
        "model = LogisticRegression(random_state=0, solver='liblinear')\n",
        "\n",
        "# Fit the model to training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make prediction using the trained model\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j-Abw7JOqD_"
      },
      "source": [
        "## Performance of the model (30 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akg9LvP5DGE8"
      },
      "source": [
        "Your task is to report train, val, test accuracies and F1 scores. **You are required to implement `accuracy_score` and `f1_score` methods without using built-in python functions.** \n",
        "\n",
        "Your model should achieve at least **0.95** test accuracy and **0.90** test F1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chqVbKH6kZyY"
      },
      "source": [
        "def accuracy_score(y_true, y_pred): \n",
        "    # Calculate accuracy of the model's prediction\n",
        "    \"\"\"\n",
        "    YOUR CODE GOES HERE\n",
        "    \"\"\"\n",
        "    accuracy = None\n",
        "    return accuracy\n",
        "\n",
        "def f1_score(y_true, y_pred): \n",
        "    # Calculate F1 score of the model's prediction\n",
        "    \"\"\"\n",
        "    YOUR CODE GOES HERE\n",
        "    \"\"\"\n",
        "    f1 = None\n",
        "    return f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqrMw0udDD04"
      },
      "source": [
        "print(f\"Training accuracy: {accuracy_score(y_train, y_train_pred):.3f}, \"\n",
        "      f\"F1 score: {f1_score(y_train, y_train_pred):.3f}\")\n",
        "print(f\"Validation accuracy: {accuracy_score(y_val, y_val_pred):.3f}, \"\n",
        "      f\"F1 score: {f1_score(y_val, y_val_pred):.3f}\")\n",
        "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred):.3f}, \"\n",
        "      f\"F1 score: {f1_score(y_test, y_test_pred):.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW7P84giGgP4"
      },
      "source": [
        "**Question.**\n",
        "Is accuracy the metric that logistic regression optimizes while training? If no, which metric is optimized in logistic regression?\n",
        "\n",
        "**Your answer:** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak0h71krLPqX"
      },
      "source": [
        "**Question.**\n",
        "In general, does having 0.99 accuracy on test means that the model is great? If no, can you give an example of a case when the accuracy is high but the model is not good? (Hint: why do we use F1 score?)\n",
        "\n",
        "**Your answer:** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_RDI0qdOxwM"
      },
      "source": [
        "### Exploration of predicitons (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHR2OqYCDOxs"
      },
      "source": [
        "Show a few examples with true+predicted labels on the train and val sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yv8GD-UGXvR"
      },
      "source": [
        "\"\"\"\n",
        "YOUR CODE GOES HERE\n",
        "\"\"\"\n",
        "# 1 - spam, 0 - ham\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neMQ4VR9GVL3"
      },
      "source": [
        "**Question** Print 10 examples from val set which were labeled incorrectly by the model. Why do you think the model got them wrong?\n",
        "\n",
        "**Your answer:** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ssK0jRxGY3u"
      },
      "source": [
        "\"\"\"\n",
        "YOUR CODE GOES HERE\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}