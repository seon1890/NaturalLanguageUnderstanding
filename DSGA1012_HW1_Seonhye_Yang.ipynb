{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7Z8eeN5IW9q"
   },
   "source": [
    "The deadline is 9:30am Feb 9th (Wed).   \n",
    "You should submit a `.ipynb` file with your solutions to BrightSpace.\n",
    "\n",
    "--- \n",
    "\n",
    "There are 10 extra points for \"adding extra features to your model\". But the maximum grade you can obtain in this homework is 100%. If you complete the extra-credit task, your score will be min{10+score, 100}.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "In this homework we will preprocess SMS Spam Collection Dataset and train a bag-of-words classifier (logistic regression) for spam detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZd0LJzbISPd"
   },
   "source": [
    "## Data Loading (10 points)\n",
    "\n",
    "First, we download the SMS Spam Collection Dataset. The dataset is taken from [Kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset/data#) and loaded to [Google Drive](https://drive.google.com/open?id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR) so that everyone can access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PvGErs2oHkWU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://docs.google.com/uc?export=download&id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR' -O spam.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcHV1lUwtH-n",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXVQCF-ovo4G"
   },
   "source": [
    "There are two columns: `v1` -- spam or ham indicator, `v2` -- text of the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BiKE89v0zMiY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"spam.csv\", usecols=[\"v1\", \"v2\"], encoding='latin-1')\n",
    "# 1 - spam, 0 - ham\n",
    "df.v1 = (df.v1 == \"spam\").astype(\"int\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>0</td>\n",
       "      <td>Shall i get my pouch?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>0</td>\n",
       "      <td>Am surfing online store. For offers do you wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>0</td>\n",
       "      <td>Nothing really, just making sure everybody's u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>0</td>\n",
       "      <td>Yo, you at jp and hungry like a mofo?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0</td>\n",
       "      <td>Thanks for picking up the trash.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>0</td>\n",
       "      <td>No chikku nt yet.. Ya i'm free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>0</td>\n",
       "      <td>Send me the new number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>0</td>\n",
       "      <td>Which is why i never wanted to tell you any of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0</td>\n",
       "      <td>Then she buying today? ÌÏ no need to c meh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1                                                 v2\n",
       "3700   0                              Shall i get my pouch?\n",
       "2329   0  Am surfing online store. For offers do you wan...\n",
       "2164   0  Nothing really, just making sure everybody's u...\n",
       "5357   0                                                 Ok\n",
       "3096   0              Yo, you at jp and hungry like a mofo?\n",
       "...   ..                                                ...\n",
       "775    0                   Thanks for picking up the trash.\n",
       "3725   0                     No chikku nt yet.. Ya i'm free\n",
       "4892   0                             Send me the new number\n",
       "3267   0  Which is why i never wanted to tell you any of...\n",
       "1337   0      Then she buying today? ÌÏ no need to c meh...\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle = df.sample(frac=1) #use this to shuffle the dataset\n",
    "shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXQhTzrCv-Nk"
   },
   "source": [
    "Your task is to split the data to train/dev/test (don't forget to shuffle the data). Make sure that each row appears only in one of the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ga5Qydpw-gdQ"
   },
   "outputs": [],
   "source": [
    "# 0.15 for val, 0.15 for test, 0.7 for train\n",
    "val_size = int(df.shape[0] * 0.15)\n",
    "test_size = int(df.shape[0] * 0.15)\n",
    "\n",
    "\n",
    "# splitting the data\n",
    "val = shuffle[:val_size]\n",
    "test = shuffle[val_size:val_size + test_size]\n",
    "train = shuffle[val_size + test_size:]\n",
    "\n",
    "\n",
    "train_texts, train_labels = train[:][\"v2\"], train[:][\"v1\"]\n",
    "val_texts, val_labels     = val[:][\"v2\"], val[:][\"v1\"]\n",
    "test_texts, test_labels   = test[:][\"v2\"], test[:][\"v1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGyHG4lBISP2"
   },
   "source": [
    "## Data Processing (40 points)\n",
    "\n",
    "The task is to create bag-of-words features: tokenize the text, index each token, represent the sentence as a dictionary of tokens and their counts, limit the vocabulary to $n$ most frequent tokens. In the lab we use built-in `sklearn` function, `sklearn.feature_extraction.text.CountVectorizer`. \n",
    "**In this HW, you are required to implement the `Vectorizer` on your own without using `sklearn` built-in functions.**\n",
    "\n",
    "Function `preprocess_data` takes the list of texts and returns list of (lists of tokens). \n",
    "You may use [spacy](https://spacy.io/) or [nltk](https://www.nltk.org/) text processing libraries in `preprocess_data` function. \n",
    "\n",
    "Class `Vectorizer` is used to vectorize the text and to create a matrix of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/seonhyeyang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "793EFaQYhHeR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/seonhyeyang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/seonhyeyang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/seonhyeyang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data):\n",
    "    # This function should return a list of lists of preprocessed tokens for each message\n",
    "    \n",
    "    nltk.download(\"punkt\")\n",
    "    result = []\n",
    "    for word in data:\n",
    "        result.append(nltk.word_tokenize(word))\n",
    "    \n",
    "    preprocessed_data = result\n",
    "    return preprocessed_data\n",
    "\n",
    "train_data = preprocess_data(train_texts)\n",
    "val_data = preprocess_data(val_texts)\n",
    "test_data = preprocess_data(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uw8z2TjpS3Pv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TM2qpOKpjVbD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Vectorizer():\n",
    "    def __init__(self, max_features):\n",
    "        self.max_features = max_features\n",
    "        self.vocab_list = None\n",
    "        self.token_to_index = None\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        # Create a vocab list, self.vocab_list, using the most frequent \"max_features\" tokens\n",
    "        # Create a token indexer, self.token_to_index, that will map each token in self.vocab \n",
    "        # to its corresponding index in self.vocab_list\n",
    "        d = []\n",
    "        for s in dataset:\n",
    "            for t in s:\n",
    "                d.append(t)\n",
    "        \n",
    "        \n",
    "        w, c = np.unique(d, return_counts=True)\n",
    "        \n",
    "        self.vocab_list = []\n",
    "        for i, w in sorted(zip(c, w), reverse=True):\n",
    "            self.vocab_list.append(w)\n",
    "        self.token_to_index = {}\n",
    "        for i, w in enumerate(self.vocab_list):\n",
    "            self.token_to_index[w] = i\n",
    "        \n",
    "        \n",
    "    def transform(self, dataset):\n",
    "        # This function transforms text dataset into a matrix, data_matrix\n",
    "        data_matrix = np.zeros((len(dataset), len(self.vocab_list)))\n",
    "        \n",
    "        for i, d in enumerate(dataset):\n",
    "            for t in d:\n",
    "                if t in self.token_to_index:\n",
    "                    data_matrix[i, self.token_to_index[t]] = 1\n",
    "        \n",
    "        \n",
    "        return data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "wXMrZXlZjcH7"
   },
   "outputs": [],
   "source": [
    "max_features = 750 # TODO: Replace None with a number\n",
    "vectorizer = Vectorizer(max_features=max_features)\n",
    "vectorizer.fit(train_data)\n",
    "X_train = vectorizer.transform(train_data)\n",
    "X_val = vectorizer.transform(val_data)\n",
    "X_test = vectorizer.transform(test_data)\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "vocab = vectorizer.vocab_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGLg6udky1zo"
   },
   "source": [
    "(10 extra points) You can add more features to the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s80GgEm6F5DG"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "YOUR CODE GOES HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wtm7a6JWu9-3"
   },
   "source": [
    "## Model\n",
    "\n",
    "We train logistic regression model and save prediction for train, val and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Wq9stSAbAIZe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seonhyeyang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n",
      "/Users/seonhyeyang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n",
      "/Users/seonhyeyang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define Logistic Regression model\n",
    "model = LogisticRegression(random_state=0, solver='liblinear')\n",
    "\n",
    "# Fit the model to training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained model\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3j-Abw7JOqD_"
   },
   "source": [
    "## Performance of the model (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Akg9LvP5DGE8"
   },
   "source": [
    "Your task is to report train, val, test accuracies and F1 scores. **You are required to implement `accuracy_score` and `f1_score` methods without using built-in python functions.** \n",
    "\n",
    "Your model should achieve at least **0.95** test accuracy and **0.90** test F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "chqVbKH6kZyY"
   },
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred): \n",
    "    # Calculate accuracy of the model's prediction\n",
    "    accuracy = (y_true == y_pred).sum()  / len(y_true) #correct predictions/#total predictions\n",
    "    return accuracy\n",
    "\n",
    "def f1_score(y_true, y_pred): \n",
    "    # Calculate F1 score of the model's prediction\n",
    "    t = ((y_true == 1) & (y_pred == 1)).sum()\n",
    "    p = (y_pred == 1).sum()\n",
    "    ps = (y_true == 1).sum()\n",
    "    pres = t / p\n",
    "    if ps <= 0:\n",
    "        pres = 0\n",
    "    r = t / ps\n",
    "    if ps <= 0:\n",
    "        r = 0\n",
    "        \n",
    "    f1 = 2 / ((1 / pres) + (1/r))\n",
    "    if pres <= 0 or r <=0:\n",
    "        f1 = 0\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "MqrMw0udDD04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.998, F1 score: 0.994\n",
      "Validation accuracy: 0.978, F1 score: 0.912\n",
      "Test accuracy: 0.989, F1 score: 0.954\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training accuracy: {accuracy_score(y_train, y_train_pred):.3f}, \"\n",
    "      f\"F1 score: {f1_score(y_train, y_train_pred):.3f}\")\n",
    "print(f\"Validation accuracy: {accuracy_score(y_val, y_val_pred):.3f}, \"\n",
    "      f\"F1 score: {f1_score(y_val, y_val_pred):.3f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred):.3f}, \"\n",
    "      f\"F1 score: {f1_score(y_test, y_test_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FW7P84giGgP4"
   },
   "source": [
    "**Question.**\n",
    "Is accuracy the metric that logistic regression optimizes while training? If no, which metric is optimized in logistic regression?\n",
    "\n",
    "**Your answer:** logistic regression is a statistical model that uses logistic function to model a binary output such as pass/fail. Logistic regression minimizes the negative log of the likelihood of the correct output and maximizes the liklihood of the correct output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ak0h71krLPqX"
   },
   "source": [
    "**Question.**\n",
    "In general, does having 0.99 accuracy on test means that the model is great? If no, can you give an example of a case when the accuracy is high but the model is not good? (Hint: why do we use F1 score?)\n",
    "\n",
    "**Your answer:** Just because a model has 0.99 accuracy on a test that does not mean the model is ideal or great. For example, if we had a dataset of 1000 students based on sex (male or female) and the ratio was 990:10 male to female respectively. Then we would have a high accuracy on males but a low accuracy for females. It's important that our data has balance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_RDI0qdOxwM"
   },
   "source": [
    "### Exploration of predicitons (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHR2OqYCDOxs"
   },
   "source": [
    "Show a few examples with true+predicted labels on the train and val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "5yv8GD-UGXvR"
   },
   "outputs": [],
   "source": [
    "# 1 - spam, 0 - ham\n",
    "t = 1\n",
    "f = 0\n",
    "tcs = train_texts.iloc[np.where((y_train == y_train_pred) & (y_train == t))]\n",
    "tch = train_texts.iloc[np.where((y_train == y_train_pred) & (y_train == f))]\n",
    "vcs = val_texts.iloc[np.where((y_val == y_val_pred) & (y_val == t))]\n",
    "vch = val_texts.iloc[np.where((y_val == y_val_pred) & (y_val == f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow\n",
      "Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! C Suprman V, Matrix3, StarWars3, etc all 4 FREE! bx420-ip4-5we. 150pm. Dont miss out! \n",
      "Kit Strip - you have been billed 150p. Netcollex Ltd. PO Box 1013 IG11 OJA\n",
      "Congratulations YOU'VE Won. You're a Winner in our August å£1000 Prize Draw. Call 09066660100 NOW. Prize Code 2309.\n",
      "Do you want a New Nokia 3510i Colour Phone Delivered Tomorrow? With 200 FREE minutes to any mobile + 100 FREE text + FREE camcorder Reply or Call 8000930705\n",
      "Todays Voda numbers ending 7548 are selected to receive a $350 award. If you have a match please call 08712300220 quoting claim code 4041 standard rates app\n",
      "PRIVATE! Your 2003 Account Statement for shows 800 un-redeemed S. I. M. points. Call 08718738002 Identifier Code: 48922 Expires 21/11/04\n",
      "No. 1 Nokia Tone 4 ur mob every week! Just txt NOK to 87021. 1st Tone FREE ! so get txtin now and tell ur friends. 150p/tone. 16 reply HL 4info\n",
      "Had your contract mobile 11 Mnths? Latest Motorola, Nokia etc. all FREE! Double Mins & Text on Orange tariffs. TEXT YES for callback, no to remove from records\n",
      "Send a logo 2 ur lover - 2 names joined by a heart. Txt LOVE NAME1 NAME2 MOBNO eg LOVE ADAM EVE 07123456789 to 87077 Yahoo! POBox36504W45WQ TxtNO 4 no ads 150p.\n",
      "XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL\n",
      "Urgent Urgent! We have 800 FREE flights to Europe to give away, call B4 10th Sept & take a friend 4 FREE. Call now to claim on 09050000555. BA128NNFWFLY150ppm\n",
      "You have won a guaranteed å£200 award or even å£1000 cashto claim UR award call free on 08000407165 (18+) 2 stop getstop on 88222 PHP. RG21 4JX\n",
      "Loan for any purpose å£500 - å£75,000. Homeowners + Tenants welcome. Have you been previously refused? We can still help. Call Free 0800 1956669 or text back 'help'\n",
      "Do you want 750 anytime any network mins 150 text and a NEW VIDEO phone for only five pounds per week call 08002888812 or reply for delivery tomorrow\n",
      "As a valued customer, I am pleased to advise you that following recent review of your Mob No. you are awarded with a å£1500 Bonus Prize, call 09066368470\n",
      "\\URGENT! This is the 2nd attempt to contact U!U have WON å£1000CALL 09071512432 b4 300603t&csBCM4235WC1N3XX.callcost150ppmmobilesvary. maxå£7. 50\\\"\"\n",
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "Check Out Choose Your Babe Videos @ sms.shsex.netUN fgkslpoPW fgkslpo\n",
      "SMSSERVICES. for yourinclusive text credits, pls goto www.comuk.net login= 3qxj9 unsubscribe with STOP, no extra charge. help 08702840625.COMUK. 220-CM2 9AE\n"
     ]
    }
   ],
   "source": [
    "#spam\n",
    "for i in range(10):\n",
    "    print(tcs.iloc[i])\n",
    "    print(vcs.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its  &lt;#&gt; k here oh. Should i send home for sale.\n",
      "Nice line said by a broken heart- Plz don't cum 1 more times infront of me... Other wise once again I ll trust U... Good 9t:)\n",
      "Awesome, plan to get here any time after like  &lt;#&gt; , I'll text you details in a wee bit\n",
      "Did u find out what time the bus is at coz i need to sort some stuff out.\n",
      "This pay is  &lt;DECIMAL&gt;  lakhs:)\n",
      "Hi i won't b ard 4 christmas. But do enjoy n merry x'mas.\n",
      "I think its far more than that but find out. Check google maps for a place from your dorm.\n",
      "Come to mahal bus stop.. &lt;DECIMAL&gt;\n",
      "Good. do you think you could send me some pix? I would love to see your top and bottom...\n",
      "Your pussy is perfect!\n",
      "Hi.:)technical support.providing assistance to us customer through call and email:)\n",
      "My supervisor find 4 me one lor i thk his students. I havent ask her yet. Tell u aft i ask her.\n",
      "Well am officially in a philosophical hole, so if u wanna call am at home ready to be saved!\n",
      "Wat r u doing now?\n",
      "Ultimately tor motive tui achieve korli.\n",
      "She is our sister.. She belongs 2 our family.. She is d hope of tomorrow.. Pray 4 her,who was fated 4 d Shoranur train incident. Lets hold our hands together &amp; fuelled by love &amp; concern prior 2 her grief &amp; pain. Pls join in dis chain &amp; pass it. STOP VIOLENCE AGAINST WOMEN.\n",
      "Cant think of anyone with * spare room off * top of my head\n",
      "Ok i shall talk to him\n",
      "Machan you go to gym tomorrow,  i wil come late goodnight.\n",
      "Yes I started to send requests to make it but pain came back so I'm back in bed. Double coins at the factory too. I gotta cash in all my nitros.\n"
     ]
    }
   ],
   "source": [
    "#ham\n",
    "for i in range(10):\n",
    "    print(tch.iloc[i])\n",
    "    print(vch.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neMQ4VR9GVL3"
   },
   "source": [
    "**Question** Print 10 examples from val set which were labeled incorrectly by the model. Why do you think the model got them wrong?\n",
    "\n",
    "**Your answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled incorrectly by the model: Nice line said by a broken heart- Plz don't cum 1 more times infront of me... Other wise once again I ll trust U... Good 9t:)\n",
      "labeled incorrectly by the model: Did u find out what time the bus is at coz i need to sort some stuff out.\n",
      "labeled incorrectly by the model: Hi i won't b ard 4 christmas. But do enjoy n merry x'mas.\n",
      "labeled incorrectly by the model: Come to mahal bus stop.. &lt;DECIMAL&gt;\n",
      "labeled incorrectly by the model: Your pussy is perfect!\n",
      "labeled incorrectly by the model: My supervisor find 4 me one lor i thk his students. I havent ask her yet. Tell u aft i ask her.\n",
      "labeled incorrectly by the model: Wat r u doing now?\n",
      "labeled incorrectly by the model: She is our sister.. She belongs 2 our family.. She is d hope of tomorrow.. Pray 4 her,who was fated 4 d Shoranur train incident. Lets hold our hands together &amp; fuelled by love &amp; concern prior 2 her grief &amp; pain. Pls join in dis chain &amp; pass it. STOP VIOLENCE AGAINST WOMEN.\n",
      "labeled incorrectly by the model: Ok i shall talk to him\n",
      "labeled incorrectly by the model: Yes I started to send requests to make it but pain came back so I'm back in bed. Double coins at the factory too. I gotta cash in all my nitros.\n"
     ]
    }
   ],
   "source": [
    "val = np.array(val_texts)\n",
    "\n",
    "x = 0\n",
    "num = 10\n",
    "for i in range(num):\n",
    "  if y_val[x] == y_val_pred[x]:\n",
    "    x += 1\n",
    "  print(\"labeled incorrectly by the model:\", val[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSGA1012-HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
